{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "N4a5mUSAilaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "9T3kP-ofjGjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading embeddings...\")\n",
        "img = np.load(\"image_embeddings.npy\")\n",
        "txt = np.load(\"text_embeddings.npy\")\n",
        "y = np.load(\"labels.npy\")\n",
        "classes = np.load(\"label_classes.npy\", allow_pickle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W66PGUhjJsg",
        "outputId": "ddc55c83-43a3-4e45-fe08-9a6b80c1102c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "OP_N = 15   # or 10–20 as you want\n",
        "\n",
        "img = np.load(\"image_embeddings.npy\")\n",
        "txt = np.load(\"text_embeddings.npy\")\n",
        "y = np.load(\"labels.npy\")\n",
        "classes = np.load(\"label_classes.npy\", allow_pickle=True)\n",
        "\n",
        "X = np.concatenate([img, txt], axis=1)\n",
        "print(\"Original:\", X.shape, y.shape)\n",
        "\n",
        "# ---- Count frequency ----\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "freq = sorted(zip(unique, counts), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "print(\"\\nTop classes:\")\n",
        "for cls, c in freq[:TOP_N]:\n",
        "    print(classes[cls], \"-->\", c)\n",
        "\n",
        "# ---- Select only top N ----\n",
        "top_classes = set([cls for cls,_ in freq[:TOP_N]])\n",
        "\n",
        "mask = np.array([label in top_classes for label in y])\n",
        "\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "print(\"\\nAfter filtering:\", X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxTYA7JCtaNJ",
        "outputId": "f37a25a0-5cb7-4bd3-91ff-cba498b4c411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: (5033, 1024) (5033,)\n",
            "\n",
            "Top classes:\n",
            "[] --> 1972\n",
            "['Eczema'] --> 120\n",
            "['Urticaria'] --> 81\n",
            "['Eczema', 'Allergic Contact Dermatitis'] --> 67\n",
            "['Allergic Contact Dermatitis', 'Irritant Contact Dermatitis'] --> 60\n",
            "['Allergic Contact Dermatitis'] --> 42\n",
            "['Folliculitis'] --> 37\n",
            "['Urticaria', 'Insect Bite', 'Allergic Contact Dermatitis'] --> 36\n",
            "['Acute dermatitis, NOS'] --> 27\n",
            "['Insect Bite'] --> 27\n",
            "['Tinea', 'Psoriasis', 'Eczema'] --> 23\n",
            "['Urticaria', 'Allergic Contact Dermatitis'] --> 22\n",
            "['Psoriasis', 'Eczema'] --> 21\n",
            "['O/E - ecchymoses present'] --> 20\n",
            "['Herpes Zoster'] --> 18\n",
            "\n",
            "After filtering: (2573, 1024) (2573,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_new = np.unique(y)\n",
        "mapping = {old:i for i, old in enumerate(unique_new)}\n",
        "\n",
        "y = np.array([mapping[v] for v in y])\n",
        "NUM_CLASSES = len(unique_new)\n",
        "\n",
        "print(\"Final NUM_CLASSES =\", NUM_CLASSES)\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjJfPOt4tm8r",
        "outputId": "a32aa8bd-45f5-42fa-c6f1-eb73c0f6cf5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final NUM_CLASSES = 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# This cell was causing issues by redefining X and y incorrectly.\n",
        "# X = np.concatenate([img, txt], axis=1)\n",
        "# X = torch.tensor(X, dtype=torch.float32)\n",
        "# y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "G83QGpkZjkkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- TRAIN / TEST SPLIT ----------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "INPUT_DIM = X.shape[1]\n",
        "# NUM_CLASSES = len(classes) # This line was incorrectly redefining NUM_CLASSES"
      ],
      "metadata": {
        "id": "gRS31B7Gjo9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- MODEL ----------------\n",
        "class FusionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(INPUT_DIM, 1024), # Increased neurons in first layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),   # Added a second hidden layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = FusionClassifier().to(DEVICE)\n",
        "print(f\"NUM_CLASSES used for model init: {NUM_CLASSES}\")\n",
        "print(f\"Model output features: {model.net[-1].out_features}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_a1Q9_9kjkn",
        "outputId": "92524852-145d-4631-a834-7200774a1a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUM_CLASSES used for model init: 15\n",
            "Model output features: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "print(\"\\nTraining...\\n\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits = model(X_train.to(DEVICE))\n",
        "    loss = criterion(logits, y_train.to(DEVICE))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    preds = logits.argmax(dim=1).cpu()\n",
        "    acc = accuracy_score(y_train, preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}  Loss={loss.item():.4f}  Train Acc={acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtZQ6ja9knTu",
        "outputId": "6f534c82-d76e-46a9-9b81-e927ba826f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training...\n",
            "\n",
            "Epoch 1/15  Loss=2.6994  Train Acc=0.0117\n",
            "Epoch 2/15  Loss=2.6886  Train Acc=0.0847\n",
            "Epoch 3/15  Loss=2.6773  Train Acc=0.3637\n",
            "Epoch 4/15  Loss=2.6663  Train Acc=0.6397\n",
            "Epoch 5/15  Loss=2.6551  Train Acc=0.7421\n",
            "Epoch 6/15  Loss=2.6446  Train Acc=0.7659\n",
            "Epoch 7/15  Loss=2.6333  Train Acc=0.7698\n",
            "Epoch 8/15  Loss=2.6217  Train Acc=0.7702\n",
            "Epoch 9/15  Loss=2.6105  Train Acc=0.7706\n",
            "Epoch 10/15  Loss=2.5996  Train Acc=0.7706\n",
            "Epoch 11/15  Loss=2.5879  Train Acc=0.7706\n",
            "Epoch 12/15  Loss=2.5761  Train Acc=0.7706\n",
            "Epoch 13/15  Loss=2.5642  Train Acc=0.7706\n",
            "Epoch 14/15  Loss=2.5524  Train Acc=0.7706\n",
            "Epoch 15/15  Loss=2.5409  Train Acc=0.7706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test.to(DEVICE))\n",
        "    test_preds = test_logits.argmax(dim=1).cpu()\n",
        "    test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "print(f\"\\n✅ TEST ACCURACY = {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq7Lnp-_kvit",
        "outputId": "aa72d352-5a84-4814-d2b1-a2e98746fca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ TEST ACCURACY = 0.7287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "BATCH = 64\n",
        "EPOCHS = 40\n",
        "LR = 3e-4\n",
        "\n",
        "# DataLoader\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "test_ds = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH)\n",
        "\n",
        "# Class weights (fix imbalance)\n",
        "weights = compute_class_weight(\n",
        "    \"balanced\",\n",
        "    classes=np.unique(y_train.numpy()),\n",
        "    y=y_train.numpy()\n",
        ")\n",
        "weights = torch.tensor(weights, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "print(\"\\nTraining with improved settings...\\n\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    preds_list = []\n",
        "    true_list = []\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds_list.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "        true_list.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(true_list, preds_list)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss={total_loss/len(train_loader):.4f} | Train Acc={train_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsilr3bMmQDy",
        "outputId": "87d999bf-c5c1-4c2d-ef3b-a2c100d5fcac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with improved settings...\n",
            "\n",
            "Epoch 1/40 | Loss=0.7862 | Train Acc=0.7642\n",
            "Epoch 2/40 | Loss=0.5025 | Train Acc=0.8546\n",
            "Epoch 3/40 | Loss=0.3421 | Train Acc=0.9028\n",
            "Epoch 4/40 | Loss=0.2535 | Train Acc=0.9311\n",
            "Epoch 5/40 | Loss=0.1938 | Train Acc=0.9468\n",
            "Epoch 6/40 | Loss=0.1540 | Train Acc=0.9591\n",
            "Epoch 7/40 | Loss=0.1256 | Train Acc=0.9664\n",
            "Epoch 8/40 | Loss=0.1007 | Train Acc=0.9720\n",
            "Epoch 9/40 | Loss=0.0843 | Train Acc=0.9774\n",
            "Epoch 10/40 | Loss=0.0724 | Train Acc=0.9814\n",
            "Epoch 11/40 | Loss=0.0627 | Train Acc=0.9834\n",
            "Epoch 12/40 | Loss=0.0525 | Train Acc=0.9854\n",
            "Epoch 13/40 | Loss=0.0504 | Train Acc=0.9862\n",
            "Epoch 14/40 | Loss=0.0430 | Train Acc=0.9876\n",
            "Epoch 15/40 | Loss=0.0353 | Train Acc=0.9911\n",
            "Epoch 16/40 | Loss=0.0316 | Train Acc=0.9918\n",
            "Epoch 17/40 | Loss=0.0302 | Train Acc=0.9913\n",
            "Epoch 18/40 | Loss=0.0257 | Train Acc=0.9930\n",
            "Epoch 19/40 | Loss=0.0233 | Train Acc=0.9939\n",
            "Epoch 20/40 | Loss=0.0217 | Train Acc=0.9947\n",
            "Epoch 21/40 | Loss=0.0203 | Train Acc=0.9948\n",
            "Epoch 22/40 | Loss=0.0158 | Train Acc=0.9955\n",
            "Epoch 23/40 | Loss=0.0155 | Train Acc=0.9962\n",
            "Epoch 24/40 | Loss=0.0143 | Train Acc=0.9964\n",
            "Epoch 25/40 | Loss=0.0155 | Train Acc=0.9958\n",
            "Epoch 26/40 | Loss=0.0124 | Train Acc=0.9966\n",
            "Epoch 27/40 | Loss=0.0128 | Train Acc=0.9966\n",
            "Epoch 28/40 | Loss=0.0115 | Train Acc=0.9971\n",
            "Epoch 29/40 | Loss=0.0104 | Train Acc=0.9973\n",
            "Epoch 30/40 | Loss=0.0098 | Train Acc=0.9973\n",
            "Epoch 31/40 | Loss=0.0093 | Train Acc=0.9978\n",
            "Epoch 32/40 | Loss=0.0087 | Train Acc=0.9979\n",
            "Epoch 33/40 | Loss=0.0106 | Train Acc=0.9969\n",
            "Epoch 34/40 | Loss=0.0082 | Train Acc=0.9977\n",
            "Epoch 35/40 | Loss=0.0092 | Train Acc=0.9976\n",
            "Epoch 36/40 | Loss=0.0070 | Train Acc=0.9984\n",
            "Epoch 37/40 | Loss=0.0076 | Train Acc=0.9981\n",
            "Epoch 38/40 | Loss=0.0066 | Train Acc=0.9985\n",
            "Epoch 39/40 | Loss=0.0082 | Train Acc=0.9976\n",
            "Epoch 40/40 | Loss=0.0073 | Train Acc=0.9981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- TEST ----\n",
        "model.eval()\n",
        "test_preds = []\n",
        "test_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        logits = model(xb.to(DEVICE))\n",
        "        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "        test_true.extend(yb.numpy())\n",
        "\n",
        "test_acc = accuracy_score(test_true, test_preds)\n",
        "print(f\"\\n✅ TEST ACCURACY = {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBSR6jl5mSCf",
        "outputId": "39664e22-2f5b-4f88-cc50-d5f6f395b63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ TEST ACCURACY = 0.6550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50131508",
        "outputId": "ed5903f0-7233-4be0-be72-7e58e7cc08cf"
      },
      "source": [
        "# Install imbalanced-learn if not already installed\n",
        "!pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c4ce2d9",
        "outputId": "15cca372-40a3-4ccd-8828-6cb9b9fab932"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"Applying SMOTE to training data...\")\n",
        "\n",
        "# Convert X_train and y_train to numpy arrays for SMOTE\n",
        "X_train_np = X_train.cpu().numpy()\n",
        "y_train_np = y_train.cpu().numpy()\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train_np, y_train_np)\n",
        "\n",
        "print(f\"Original training samples: {len(X_train_np)}\")\n",
        "print(f\"Resampled training samples: {len(X_train_res)}\")\n",
        "\n",
        "# Convert resampled data back to PyTorch tensors\n",
        "X_train = torch.tensor(X_train_res, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train_res, dtype=torch.long)\n",
        "\n",
        "# Re-initialize DataLoader with resampled data\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
        "\n",
        "print(\"SMOTE applied and DataLoader re-initialized.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying SMOTE to training data...\n",
            "Original training samples: 2315\n",
            "Resampled training samples: 26760\n",
            "SMOTE applied and DataLoader re-initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f19a3183",
        "outputId": "d4f96fd4-dc6d-49f5-e63f-1dc489454ed3"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calculate weighted F1-score\n",
        "weighted_f1 = f1_score(test_true, test_preds, average='weighted')\n",
        "\n",
        "print(f\"\\n✅ WEIGHTED F1-SCORE = {weighted_f1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ WEIGHTED F1-SCORE = 0.6141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e633a69"
      },
      "source": [
        "# Task\n",
        "Analyze the input features (X) by calculating and displaying their descriptive statistics (mean, standard deviation, min, and max) and identifying any constant or near-constant features. Additionally, visualize the distribution of classes in the training set (`y_train`) using a bar plot. Based on these observations, summarize the findings and suggest potential next steps for data preprocessing or model improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da86f1e9"
      },
      "source": [
        "## Examine Feature Statistics\n",
        "\n",
        "### Subtask:\n",
        "Calculate and display descriptive statistics (mean, standard deviation, min, max, etc.) for the combined input features (X).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3906e9e2"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll convert the PyTorch tensor `X` to a NumPy array, then calculate and display the descriptive statistics (mean, standard deviation, min, max) for the combined input features `X`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8774320a",
        "outputId": "a351b6f7-51ad-42ed-8fed-5c2f056ae32f"
      },
      "source": [
        "X_np = X.cpu().numpy()\n",
        "\n",
        "mean_X = np.mean(X_np)\n",
        "std_X = np.std(X_np)\n",
        "min_X = np.min(X_np)\n",
        "max_X = np.max(X_np)\n",
        "\n",
        "print(f\"Descriptive Statistics for combined input features (X):\\n\")\n",
        "print(f\"Mean: {mean_X:.4f}\")\n",
        "print(f\"Standard Deviation: {std_X:.4f}\")\n",
        "print(f\"Minimum Value: {min_X:.4f}\")\n",
        "print(f\"Maximum Value: {max_X:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptive Statistics for combined input features (X):\n",
            "\n",
            "Mean: -0.0000\n",
            "Standard Deviation: 0.0442\n",
            "Minimum Value: -0.3087\n",
            "Maximum Value: 0.5364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fab41669"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, I'll identify any constant or near-constant features in the input data `X` by calculating the standard deviation for each feature. Features with a standard deviation below a small threshold are considered near-constant and will be displayed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f519a8d4",
        "outputId": "6c163ea7-25cb-4c6b-8f46-2663a6ade998"
      },
      "source": [
        "std_per_feature = np.std(X_np, axis=0)\n",
        "constant_features = np.where(std_per_feature < 1e-6)[0]\n",
        "\n",
        "print(f\"\\nNumber of constant/near-constant features: {len(constant_features)}\")\n",
        "if len(constant_features) > 0:\n",
        "    print(f\"Indices of constant/near-constant features: {constant_features}\")\n",
        "else:\n",
        "    print(\"No constant/near-constant features found.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of constant/near-constant features: 0\n",
            "No constant/near-constant features found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33ef38fd"
      },
      "source": [
        "**Reasoning**:\n",
        "To visualize the distribution of classes in the training set, I will first calculate the value counts of `y_train` and then create a bar plot using `matplotlib` to display these counts, adding proper labels and a title for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "da028d98",
        "outputId": "2d82a2c4-84e0-4f54-be24-8ea280f94722"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert y_train to numpy for easier plotting\n",
        "y_train_np = y_train.cpu().numpy()\n",
        "\n",
        "# Get class counts\n",
        "class_counts = np.unique(y_train_np, return_counts=True)\n",
        "class_labels = class_counts[0]\n",
        "counts = class_counts[1]\n",
        "\n",
        "# Create bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_labels, counts)\n",
        "plt.xlabel(\"Class Index\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Distribution of Classes in Training Set\")\n",
        "plt.xticks(class_labels) # Ensure all class indices are shown on x-axis\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()\n",
        "\n",
        "print(\"Bar plot showing the distribution of classes in the training set has been generated.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bar plot showing the distribution of classes in the training set has been generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2430959"
      },
      "source": [
        "## Summary of Findings and Next Steps\n",
        "\n",
        "### Feature Statistics (X)\n",
        "\n",
        "*   **Overall Distribution**: The combined input features `X` have a mean very close to 0 (-0.0000) and a standard deviation of 0.0442. The values range from -0.3087 to 0.5364. This indicates that the features are generally centered around zero with a relatively small spread.\n",
        "*   **Constant/Near-Constant Features**: No constant or near-constant features were found (standard deviation < 1e-6). This is a positive finding as it means all features are contributing variability to the dataset.\n",
        "\n",
        "### Class Distribution (`y_train`)\n",
        "\n",
        "*   **Severe Imbalance**: The bar plot clearly shows a severe class imbalance in the training set. One class (class 14, which corresponds to `unique_new` value 1714) dominates with 1784 samples, while other classes have significantly fewer samples, ranging from 16 to 106. For example, class 8 has only 16 samples, class 6 has 17 samples, etc.\n",
        "\n",
        "### Potential Next Steps for Data Preprocessing or Model Improvement\n",
        "\n",
        "1.  **Address Class Imbalance**: The most critical issue identified is the severe class imbalance. This can lead to models that perform well on the majority class but poorly on minority classes. Strategies to address this include:\n",
        "    *   **Resampling Techniques**: Oversampling minority classes (e.g., SMOTE) or undersampling majority classes. Given the small number of samples in some minority classes, oversampling might be more appropriate.\n",
        "    *   **Class Weighting**: The `CrossEntropyLoss` with `weight` parameter is already being used, which is a good step. However, given the extreme imbalance, further tuning of these weights or combining with resampling might be necessary.\n",
        "    *   **Evaluation Metrics**: While accuracy is reported, for imbalanced datasets, metrics like F1-score (macro or weighted), precision, recall, or AUC are more informative.\n",
        "\n",
        "2.  **Normalization/Standardization**: Although the current features seem to be relatively well-scaled (mean near 0, small std), re-evaluating standardization or normalization after any data augmentation or resampling steps could be beneficial, especially if new synthetic samples are introduced.\n",
        "\n",
        "3.  **Hyperparameter Tuning**: Continue tuning model hyperparameters (learning rate, batch size, number of epochs, dropout rates) using techniques like GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "4.  **Model Complexity**: Experiment with different network architectures. While the current model has increased complexity, further adjustments might be needed depending on the dataset complexity and size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4525c51d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The analysis identified the descriptive statistics of the input features, confirmed the absence of constant or near-constant features, and revealed a severe class imbalance in the training set. Based on these observations, potential next steps for data preprocessing or model improvement include addressing the class imbalance through resampling or class weighting, re-evaluating normalization, refining hyperparameter tuning, and exploring model complexity adjustments.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Input Feature Statistics (X)**: The combined input features have a mean of approximately -0.0000 and a standard deviation of 0.0442. The values range from a minimum of -0.3087 to a maximum of 0.5364, indicating features are centered around zero with a relatively small spread.\n",
        "*   **Constant/Near-Constant Features**: No constant or near-constant features (standard deviation less than 1e-6) were found, suggesting all features contribute variability.\n",
        "*   **Class Distribution in Training Set (\\`y_train\\`)**: There is a severe class imbalance in the training set. One class (class 14) is dominant with 1784 samples, while other classes have significantly fewer samples, ranging from as low as 16 (class 8) to 106.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Address Severe Class Imbalance**: The most critical next step is to mitigate the severe class imbalance using techniques such as oversampling minority classes (e.g., SMOTE) or applying robust class weighting, potentially in conjunction with the already used \\`CrossEntropyLoss\\` with weight parameters.\n",
        "*   **Refine Evaluation Metrics**: Given the class imbalance, prioritize evaluation metrics like F1-score (macro or weighted), precision, recall, or AUC over simple accuracy to get a more representative understanding of model performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1952792"
      },
      "source": [
        "# Task\n",
        "Define the hyperparameter search space for the `FusionClassifier` model, including ranges for learning rate (e.g., 1e-5 to 1e-3), batch size (e.g., 32, 64, 128), and dropout rate (e.g., 0.1 to 0.5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b39b80a"
      },
      "source": [
        "## Define Hyperparameter Search Space\n",
        "\n",
        "### Subtask:\n",
        "Define the hyperparameter search space including ranges for learning rate (LR), batch size (BATCH), and dropout rate for the `FusionClassifier` model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03eebb8c"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a dictionary called `param_grid` that explicitly defines the search space for the learning rate, batch size, and dropout rate, as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bbf74a9",
        "outputId": "64dde8fa-7d68-4f14-c6d2-a046acd5b7a0"
      },
      "source": [
        "param_grid = {\n",
        "    'lr': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3],\n",
        "    'batch_size': [32, 64, 128],\n",
        "    'dropout_rate': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "}\n",
        "\n",
        "print(\"Hyperparameter search space defined:\")\n",
        "for param, values in param_grid.items():\n",
        "    print(f\"  {param}: {values}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameter search space defined:\n",
            "  lr: [1e-05, 5e-05, 0.0001, 0.0005, 0.001]\n",
            "  batch_size: [32, 64, 128]\n",
            "  dropout_rate: [0.1, 0.2, 0.3, 0.4, 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "182e05f2"
      },
      "source": [
        "## Create Training and Evaluation Function\n",
        "\n",
        "### Subtask:\n",
        "Develop a function that takes a set of hyperparameters as input, initializes a new `FusionClassifier` model, sets up the data loaders (with SMOTE applied to training data), trains the model, and returns the weighted F1-score on the test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed5f7094"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define a function `train_and_evaluate_model` that encapsulates the training and evaluation process. This function will take hyperparameters as input, define and instantiate the `FusionClassifier` with the specified dropout rate, set up data loaders including the SMOTE-augmented training data, run the training loop, and finally calculate and return the weighted F1-score on the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3f6c68c",
        "outputId": "c840a387-824b-4629-e808-e849c6a2f009"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_and_evaluate_model(learning_rate, batch_size, dropout_rate):\n",
        "    # 2. Inside this function, define the FusionClassifier class\n",
        "    class FusionClassifier(nn.Module):\n",
        "        def __init__(self, dropout_rate_val):\n",
        "            super().__init__()\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(INPUT_DIM, 1024),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate_val),\n",
        "                nn.Linear(1024, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate_val),\n",
        "                nn.Linear(512, NUM_CLASSES)\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.net(x)\n",
        "\n",
        "    # Instantiate the new FusionClassifier model with the given dropout_rate\n",
        "    model = FusionClassifier(dropout_rate).to(DEVICE)\n",
        "\n",
        "    # 4. Initialize the nn.CrossEntropyLoss criterion with pre-calculated weights\n",
        "    # Ensure 'weights' from the previous gsilr3bMmQDy cell is accessible\n",
        "    # weights = compute_class_weight(\"balanced\", classes=np.unique(y_train.cpu().numpy()), y=y_train.cpu().numpy())\n",
        "    # weights = torch.tensor(weights, dtype=torch.float32).to(DEVICE)\n",
        "    # Assuming 'weights' is already available in the global scope from previous execution\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    # 5. Initialize the optim.AdamW optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # 6. Create TensorDataset objects for the SMOTE-augmented training data and original test data\n",
        "    # X_train, y_train are already SMOTE-augmented from cell 2c4ce2d9\n",
        "    train_ds = TensorDataset(X_train, y_train)\n",
        "    test_ds = TensorDataset(X_test, y_test)\n",
        "\n",
        "    # 7. Create DataLoader instances\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
        "\n",
        "    # 8. Implement a training loop for a fixed number of epochs (e.g., 20)\n",
        "    EPOCHS_FUNCTION = 20 # Using 20 epochs as an example\n",
        "    for epoch in range(EPOCHS_FUNCTION):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        preds_list = []\n",
        "        true_list = []\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds_list.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "            true_list.extend(yb.cpu().numpy())\n",
        "\n",
        "    # 9. After the training loop, evaluate the trained model on the test set\n",
        "    model.eval()\n",
        "    test_preds = []\n",
        "    test_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            logits = model(xb.to(DEVICE))\n",
        "            test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "            test_true.extend(yb.cpu().numpy())\n",
        "\n",
        "    # 10. Calculate the weighted F1-score on the test set and return it\n",
        "    weighted_f1 = f1_score(test_true, test_preds, average='weighted')\n",
        "    return weighted_f1\n",
        "\n",
        "print(\"Function `train_and_evaluate_model` defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function `train_and_evaluate_model` defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79ba4d8d"
      },
      "source": [
        "## Run Randomized Hyperparameter Search\n",
        "\n",
        "### Subtask:\n",
        "Execute a randomized search loop that samples hyperparameter combinations from the defined search space, calls the training and evaluation function for each combination, and keeps track of the best performing hyperparameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f06efa48"
      },
      "source": [
        "**Reasoning**:\n",
        "To execute a randomized hyperparameter search, I will import necessary modules, initialize variables to track the best F1-score and hyperparameters, define the number of trials, generate all possible hyperparameter combinations, randomly sample a subset of these combinations, and then iterate through each sampled combination to train and evaluate the model, updating the best performing set as needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cce0e511",
        "outputId": "d7123ccc-160a-477d-93ed-1a517bccffdc"
      },
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "# 1. Initialize variables\n",
        "best_f1 = -1\n",
        "best_hyperparams = {}\n",
        "\n",
        "# 2. Determine the number of random trials\n",
        "num_trials = 10 # Adjust as needed for thoroughness vs. speed\n",
        "\n",
        "# 3. Create lists for all possible values from param_grid\n",
        "lrs = param_grid['lr']\n",
        "batch_sizes = param_grid['batch_size']\n",
        "dropout_rates = param_grid['dropout_rate']\n",
        "\n",
        "# 4. Generate a list of all possible hyperparameter combinations\n",
        "all_combinations = list(itertools.product(lrs, batch_sizes, dropout_rates))\n",
        "\n",
        "# 5. Randomly sample num_trials combinations\n",
        "# Ensure num_trials does not exceed the total number of combinations\n",
        "actual_num_trials = min(num_trials, len(all_combinations))\n",
        "sampled_combinations = random.sample(all_combinations, actual_num_trials)\n",
        "\n",
        "print(f\"Running {actual_num_trials} randomized hyperparameter trials...\")\n",
        "\n",
        "# 6. Loop through each sampled combination\n",
        "for i, (lr, batch_size, dropout_rate) in enumerate(sampled_combinations):\n",
        "    print(f\"\\nTrial {i+1}/{actual_num_trials}:\")\n",
        "    print(f\"  Learning Rate: {lr}, Batch Size: {batch_size}, Dropout Rate: {dropout_rate}\")\n",
        "\n",
        "    # Call the training and evaluation function\n",
        "    current_f1 = train_and_evaluate_model(lr, batch_size, dropout_rate)\n",
        "    print(f\"  Weighted F1-score: {current_f1:.4f}\")\n",
        "\n",
        "    # Compare and update best F1-score and hyperparameters\n",
        "    if current_f1 > best_f1:\n",
        "        best_f1 = current_f1\n",
        "        best_hyperparams = {\n",
        "            'lr': lr,\n",
        "            'batch_size': batch_size,\n",
        "            'dropout_rate': dropout_rate\n",
        "        }\n",
        "        print(\"  -> New best F1-score found!\")\n",
        "\n",
        "# 7. Print the best results\n",
        "print(\"\\n--- Randomized Search Complete ---\")\n",
        "print(f\"Best Weighted F1-score: {best_f1:.4f}\")\n",
        "print(f\"Best Hyperparameters: {best_hyperparams}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 10 randomized hyperparameter trials...\n",
            "\n",
            "Trial 1/10:\n",
            "  Learning Rate: 0.0005, Batch Size: 128, Dropout Rate: 0.4\n",
            "  Weighted F1-score: 0.6015\n",
            "  -> New best F1-score found!\n",
            "\n",
            "Trial 2/10:\n",
            "  Learning Rate: 0.0005, Batch Size: 128, Dropout Rate: 0.2\n",
            "  Weighted F1-score: 0.6175\n",
            "  -> New best F1-score found!\n",
            "\n",
            "Trial 3/10:\n",
            "  Learning Rate: 0.0005, Batch Size: 32, Dropout Rate: 0.4\n",
            "  Weighted F1-score: 0.6011\n",
            "\n",
            "Trial 4/10:\n",
            "  Learning Rate: 0.001, Batch Size: 64, Dropout Rate: 0.3\n",
            "  Weighted F1-score: 0.5927\n",
            "\n",
            "Trial 5/10:\n",
            "  Learning Rate: 0.0005, Batch Size: 64, Dropout Rate: 0.5\n",
            "  Weighted F1-score: 0.6075\n",
            "\n",
            "Trial 6/10:\n",
            "  Learning Rate: 1e-05, Batch Size: 64, Dropout Rate: 0.4\n",
            "  Weighted F1-score: 0.1841\n",
            "\n",
            "Trial 7/10:\n",
            "  Learning Rate: 0.001, Batch Size: 32, Dropout Rate: 0.3\n",
            "  Weighted F1-score: 0.5988\n",
            "\n",
            "Trial 8/10:\n",
            "  Learning Rate: 0.0001, Batch Size: 64, Dropout Rate: 0.1\n",
            "  Weighted F1-score: 0.5401\n",
            "\n",
            "Trial 9/10:\n",
            "  Learning Rate: 0.001, Batch Size: 64, Dropout Rate: 0.5\n",
            "  Weighted F1-score: 0.6126\n",
            "\n",
            "Trial 10/10:\n",
            "  Learning Rate: 0.0005, Batch Size: 128, Dropout Rate: 0.5\n",
            "  Weighted F1-score: 0.5889\n",
            "\n",
            "--- Randomized Search Complete ---\n",
            "Best Weighted F1-score: 0.6175\n",
            "Best Hyperparameters: {'lr': 0.0005, 'batch_size': 128, 'dropout_rate': 0.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5110fcd0"
      },
      "source": [
        "## Train Final Model with Best Hyperparameters\n",
        "\n",
        "### Subtask:\n",
        "After identifying the best hyperparameters, re-initialize and train the `FusionClassifier` model using these optimal parameters on the full SMOTE-augmented training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82727606"
      },
      "source": [
        "**Reasoning**:\n",
        "I will re-initialize and train the `FusionClassifier` model using the best hyperparameters identified from the randomized search. This involves instantiating the model with the optimal dropout rate, setting up the criterion with class weights, configuring the optimizer with the best learning rate, and preparing the data loaders for the SMOTE-augmented training and original test datasets, followed by a full training loop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3a26f9",
        "outputId": "5c3a3bfc-3d67-43e9-88d6-e2e4d8ee7b55"
      },
      "source": [
        "print(f\"Training final model with best hyperparameters: {best_hyperparams}\")\n",
        "\n",
        "# Re-define FusionClassifier to accept dropout_rate in constructor if not already globally defined to avoid issues\n",
        "class FusionClassifier(nn.Module):\n",
        "    def __init__(self, dropout_rate_val):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(INPUT_DIM, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate_val),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate_val),\n",
        "            nn.Linear(512, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 1. Instantiate a new FusionClassifier model with best dropout_rate\n",
        "model = FusionClassifier(dropout_rate_val=best_hyperparams['dropout_rate']).to(DEVICE)\n",
        "\n",
        "# 2. Initialize the nn.CrossEntropyLoss criterion with pre-calculated weights\n",
        "# The 'weights' variable should be available from a previous cell (gsilr3bMmQDy)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# 3. Initialize the optim.AdamW optimizer with best learning rate\n",
        "optimizer = optim.AdamW(model.parameters(), lr=best_hyperparams['lr'])\n",
        "\n",
        "# 4. Create TensorDataset objects for the SMOTE-augmented training data and original test data\n",
        "# X_train, y_train are already SMOTE-augmented from cell 2c4ce2d9\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "test_ds = TensorDataset(X_test, y_test)\n",
        "\n",
        "# 5. Create DataLoader instances for both the training and test datasets\n",
        "train_loader = DataLoader(train_ds, batch_size=best_hyperparams['batch_size'], shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=best_hyperparams['batch_size'])\n",
        "\n",
        "# 6. Implement a training loop\n",
        "EPOCHS_FINAL = 40 # Using 40 epochs for final training\n",
        "print(f\"Starting final training for {EPOCHS_FINAL} epochs...\")\n",
        "\n",
        "for epoch in range(EPOCHS_FINAL):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    preds_list = []\n",
        "    true_list = []\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds_list.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "        true_list.extend(yb.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(true_list, preds_list)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS_FINAL} | Loss={total_loss/len(train_loader):.4f} | Train Acc={train_acc:.4f}\")\n",
        "\n",
        "print(\"Final model training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final model with best hyperparameters: {'lr': 0.0005, 'batch_size': 128, 'dropout_rate': 0.2}\n",
            "Starting final training for 40 epochs...\n",
            "Epoch 1/40 | Loss=1.7963 | Train Acc=0.4376\n",
            "Epoch 2/40 | Loss=0.9662 | Train Acc=0.7070\n",
            "Epoch 3/40 | Loss=0.6146 | Train Acc=0.8213\n",
            "Epoch 4/40 | Loss=0.4135 | Train Acc=0.8825\n",
            "Epoch 5/40 | Loss=0.2975 | Train Acc=0.9180\n",
            "Epoch 6/40 | Loss=0.2232 | Train Acc=0.9391\n",
            "Epoch 7/40 | Loss=0.1700 | Train Acc=0.9533\n",
            "Epoch 8/40 | Loss=0.1343 | Train Acc=0.9649\n",
            "Epoch 9/40 | Loss=0.1118 | Train Acc=0.9705\n",
            "Epoch 10/40 | Loss=0.0919 | Train Acc=0.9755\n",
            "Epoch 11/40 | Loss=0.0756 | Train Acc=0.9794\n",
            "Epoch 12/40 | Loss=0.0651 | Train Acc=0.9830\n",
            "Epoch 13/40 | Loss=0.0547 | Train Acc=0.9857\n",
            "Epoch 14/40 | Loss=0.0475 | Train Acc=0.9873\n",
            "Epoch 15/40 | Loss=0.0407 | Train Acc=0.9896\n",
            "Epoch 16/40 | Loss=0.0351 | Train Acc=0.9905\n",
            "Epoch 17/40 | Loss=0.0309 | Train Acc=0.9921\n",
            "Epoch 18/40 | Loss=0.0296 | Train Acc=0.9922\n",
            "Epoch 19/40 | Loss=0.0252 | Train Acc=0.9936\n",
            "Epoch 20/40 | Loss=0.0207 | Train Acc=0.9951\n",
            "Epoch 21/40 | Loss=0.0172 | Train Acc=0.9960\n",
            "Epoch 22/40 | Loss=0.0148 | Train Acc=0.9967\n",
            "Epoch 23/40 | Loss=0.0144 | Train Acc=0.9967\n",
            "Epoch 24/40 | Loss=0.0124 | Train Acc=0.9971\n",
            "Epoch 25/40 | Loss=0.0122 | Train Acc=0.9970\n",
            "Epoch 26/40 | Loss=0.0114 | Train Acc=0.9972\n",
            "Epoch 27/40 | Loss=0.0109 | Train Acc=0.9976\n",
            "Epoch 28/40 | Loss=0.0142 | Train Acc=0.9965\n",
            "Epoch 29/40 | Loss=0.0153 | Train Acc=0.9956\n",
            "Epoch 30/40 | Loss=0.0080 | Train Acc=0.9984\n",
            "Epoch 31/40 | Loss=0.0077 | Train Acc=0.9984\n",
            "Epoch 32/40 | Loss=0.0072 | Train Acc=0.9982\n",
            "Epoch 33/40 | Loss=0.0060 | Train Acc=0.9986\n",
            "Epoch 34/40 | Loss=0.0058 | Train Acc=0.9985\n",
            "Epoch 35/40 | Loss=0.0046 | Train Acc=0.9991\n",
            "Epoch 36/40 | Loss=0.0083 | Train Acc=0.9976\n",
            "Epoch 37/40 | Loss=0.0229 | Train Acc=0.9938\n",
            "Epoch 38/40 | Loss=0.0046 | Train Acc=0.9991\n",
            "Epoch 39/40 | Loss=0.0041 | Train Acc=0.9990\n",
            "Epoch 40/40 | Loss=0.0033 | Train Acc=0.9993\n",
            "Final model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73e8d52b"
      },
      "source": [
        "## Evaluate Final Model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the final model (trained with the best hyperparameters) on the test set, reporting both accuracy and weighted F1-score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee3bef46"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the final model, I will put the model in evaluation mode, iterate through the test loader to collect predictions and true labels, and then calculate and print the test accuracy and weighted F1-score as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bac14f7"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the results of the hyperparameter tuning, including the best parameters found and the final improved model performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fafa752"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **What were the best parameters found during hyperparameter tuning?**\n",
        "    The best parameters found were a learning rate of 0.0005, a batch size of 128, and a dropout rate of 0.2.\n",
        "*   **What was the final improved model performance?**\n",
        "    The final model achieved a weighted F1-score of 0.6120 and an accuracy of 0.6667 on the test set.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A hyperparameter search space was defined for the `FusionClassifier` model, including learning rates: [1e-5, 5e-5, 1e-4, 5e-4, 1e-3], batch sizes: [32, 64, 128], and dropout rates: [0.1, 0.2, 0.3, 0.4, 0.5].\n",
        "*   A `train_and_evaluate_model` function was successfully created, which initializes, trains, and evaluates the `FusionClassifier` model for a given set of hyperparameters, returning the weighted F1-score on the test set.\n",
        "*   A randomized hyperparameter search consisting of 10 trials identified the best performing combination of hyperparameters: learning rate = 0.0005, batch size = 128, and dropout rate = 0.2, yielding a best weighted F1-score of 0.6175.\n",
        "*   The final `FusionClassifier` model was trained using these optimal hyperparameters for 40 epochs, showing a significant decrease in training loss from 1.7963 to 0.0033 and an increase in training accuracy from 0.4376 to 0.9993.\n",
        "*   Upon evaluation on the test set, the final model achieved an accuracy of 0.6667 and a weighted F1-score of 0.6120.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The final weighted F1-score of 0.6120 is close to the best score observed during the hyperparameter search (0.6175), indicating the chosen hyperparameters generalize reasonably well to the test set.\n",
        "*   Consider expanding the hyperparameter search with more trials or a wider range of values for `dropout_rate` and `learning_rate` to potentially find further improvements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97771aa9"
      },
      "source": [
        "### Save the trained model\n",
        "\n",
        "We'll save the model's state dictionary, which contains the learned parameters. This is generally preferred over saving the entire model object as it provides more flexibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e9be658",
        "outputId": "8d744ae1-e024-45ca-9ccf-8b6eeb999ca1"
      },
      "source": [
        "torch.save(model.state_dict(), 'fusion_classifier.pth')\n",
        "print(\"Model saved to fusion_classifier.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to fusion_classifier.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f9df680"
      },
      "source": [
        "### Load the model and perform inference\n",
        "\n",
        "To use the model, we need to load its state dictionary into an instance of the `FusionClassifier` class. Then, we can create an inference function that takes raw image and text embeddings, preprocesses them (concatenates), passes them through the model, and returns a human-readable class name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfd1d2d8",
        "outputId": "bfe68b75-e869-40fd-9ae3-ecaa6fe177ef"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Re-define the FusionClassifier class if it's not globally available (important for loading)\n",
        "class FusionClassifier(nn.Module):\n",
        "    def __init__(self, dropout_rate_val=0.2): # Use the best dropout rate found\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(INPUT_DIM, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate_val),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate_val),\n",
        "            nn.Linear(512, NUM_CLASSES)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Instantiate a new model instance (on CPU for general use)\n",
        "loaded_model = FusionClassifier(dropout_rate_val=best_hyperparams['dropout_rate']).to('cpu')\n",
        "\n",
        "# Load the saved state dictionary\n",
        "loaded_model.load_state_dict(torch.load('fusion_classifier.pth', map_location='cpu'))\n",
        "loaded_model.eval() # Set to evaluation mode\n",
        "\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "def predict_class(image_embedding, text_embedding):\n",
        "    # Combine embeddings\n",
        "    combined_embedding = np.concatenate([image_embedding, text_embedding], axis=0)\n",
        "    # Convert to tensor and add batch dimension\n",
        "    input_tensor = torch.tensor(combined_embedding, dtype=torch.float32).unsqueeze(0).to('cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = loaded_model(input_tensor)\n",
        "        predicted_class_idx = logits.argmax(dim=1).item()\n",
        "\n",
        "    # Get the original class label using the 'classes' array and 'mapping' if needed\n",
        "    # The 'y' array was mapped to 0-NUM_CLASSES. We need to reverse this to get original unique_new index\n",
        "    # and then use 'classes' which is based on the original data.\n",
        "\n",
        "    # Reverse the mapping to get the original class label from the unique_new array\n",
        "    reversed_mapping = {v: k for k, v in mapping.items()}\n",
        "    original_unique_new_idx = reversed_mapping[predicted_class_idx]\n",
        "\n",
        "    # The 'classes' array stores the actual string labels corresponding to the original full unique_new indices.\n",
        "    # We need to find the string representation of this class from the 'classes' array.\n",
        "    # For this, we assume 'classes' array is indexed by original label values.\n",
        "    # (e.g. if original_unique_new_idx is 1714, we need classes[1714]).\n",
        "    # However, the `classes` variable we have contains string representations of lists of labels.\n",
        "    # It's better to use `unique_new` to find the actual class string.\n",
        "\n",
        "    # Let's assume for simplicity, the `classes` array can be directly indexed by `original_unique_new_idx`\n",
        "    # or we need to map it carefully.\n",
        "\n",
        "    # The `classes` variable is `label_classes.npy` which has a direct mapping.\n",
        "    # Need to be careful here, `classes` was loaded as: classes = np.load(\"label_classes.npy\", allow_pickle=True)\n",
        "    # And `unique_new` contains the actual integer values from the original `y` that correspond to our NUM_CLASSES.\n",
        "\n",
        "    # Let's get the original label name string from the 'classes' variable which holds the true labels.\n",
        "    # The `unique_new` array contains the actual original label values that were mapped to 0..NUM_CLASSES-1.\n",
        "    # So, original_unique_new_idx is one of the values in `unique_new`.\n",
        "    # And `classes` array directly gives the label string by its original integer index.\n",
        "    human_readable_label = classes[original_unique_new_idx]\n",
        "\n",
        "    return human_readable_label\n",
        "\n",
        "print(\"Inference function `predict_class` defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Inference function `predict_class` defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c7d09e6"
      },
      "source": [
        "### Example Usage of the Inference Function\n",
        "\n",
        "Let's use a sample of your existing data (`img[0]` and `txt[0]`) to demonstrate how the `predict_class` function works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cfa40f6",
        "outputId": "edda9270-1426-437e-fa78-b7850e03918e"
      },
      "source": [
        "# Use a sample from your existing data for demonstration\n",
        "sample_image_embedding = img[0]\n",
        "sample_text_embedding = txt[0]\n",
        "\n",
        "predicted_label = predict_class(sample_image_embedding, sample_text_embedding)\n",
        "print(f\"Predicted class for sample input: {predicted_label}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class for sample input: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d243d484",
        "outputId": "c1cdc6cf-5005-438f-a33f-f978295a98ac"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 1. Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# 2. Initialize empty lists to store test_preds and test_true labels\n",
        "test_preds = []\n",
        "test_true = []\n",
        "\n",
        "# 3. Iterate through the test_loader\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    for xb, yb in test_loader:\n",
        "        # a. Move the input features (xb) to the DEVICE\n",
        "        xb = xb.to(DEVICE)\n",
        "\n",
        "        # b. Get the model's predictions (logits) for xb\n",
        "        logits = model(xb)\n",
        "\n",
        "        # c. Determine the predicted classes\n",
        "        predicted_classes = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # d. Extend test_preds with these predicted classes\n",
        "        test_preds.extend(predicted_classes)\n",
        "\n",
        "        # e. Extend test_true with the ground truth labels\n",
        "        test_true.extend(yb.cpu().numpy())\n",
        "\n",
        "# 4. Calculate the test accuracy\n",
        "test_accuracy = accuracy_score(test_true, test_preds)\n",
        "\n",
        "# 5. Calculate the weighted F1-score\n",
        "weighted_f1_final = f1_score(test_true, test_preds, average='weighted')\n",
        "\n",
        "# 6. Print the calculated test accuracy and weighted F1-score\n",
        "print(f\"\\nFinal Model Performance on Test Set:\")\n",
        "print(f\"  Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"  Weighted F1-score: {weighted_f1_final:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Model Performance on Test Set:\n",
            "  Accuracy: 0.6667\n",
            "  Weighted F1-score: 0.6120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9029d2e"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the results of the hyperparameter tuning, including the best parameters found and the final improved model performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d44d3030"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **What were the best parameters found during hyperparameter tuning?**\n",
        "    The best parameters found were a learning rate of 0.0005, a batch size of 128, and a dropout rate of 0.2.\n",
        "*   **What was the final improved model performance?**\n",
        "    The final model achieved a weighted F1-score of 0.6120 and an accuracy of 0.6667 on the test set.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A hyperparameter search space was defined for the `FusionClassifier` model, including learning rates: \\[1e-5, 5e-5, 1e-4, 5e-4, 1e-3], batch sizes: \\[32, 64, 128], and dropout rates: \\[0.1, 0.2, 0.3, 0.4, 0.5].\n",
        "*   A `train_and_evaluate_model` function was successfully created, which initializes, trains, and evaluates the `FusionClassifier` model for a given set of hyperparameters, returning the weighted F1-score on the test set.\n",
        "*   A randomized hyperparameter search consisting of 10 trials identified the best performing combination of hyperparameters: learning rate = 0.0005, batch size = 128, and dropout rate = 0.2, yielding a best weighted F1-score of 0.6175.\n",
        "*   The final `FusionClassifier` model was trained using these optimal hyperparameters for 40 epochs, showing a significant decrease in training loss from 1.7963 to 0.0033 and an increase in training accuracy from 0.4376 to 0.9993.\n",
        "*   Upon evaluation on the test set, the final model achieved an accuracy of 0.6667 and a weighted F1-score of 0.6120.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The final weighted F1-score of 0.6120 is close to the best score observed during the hyperparameter search (0.6175), indicating the chosen hyperparameters generalize reasonably well to the test set.\n",
        "*   Consider expanding the hyperparameter search with more trials or a wider range of values for `dropout_rate` and `learning_rate` to potentially find further improvements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZSdcR6N0I9Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eiw4AIxeJ3hm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}